{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "import sqlite3\n",
    "import psycopg2\n",
    "import json\n",
    "import os, zipfile\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "pd.options.display.max_columns = 100\n",
    "import datetime\n",
    "import requests\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from difflib import SequenceMatcher, get_close_matches\n",
    "from IPython.core.display import HTML\n",
    "from ua_parser import user_agent_parser\n",
    "import seaborn as sb\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "HTML(\"<style>.container { width:100% !important; }</style>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(open(\"data_verkiezingsuitslagen/index.htm\"), \"html.parser\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download all ZIP files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, a in enumerate(soup.findAll('a')):\n",
    "    #if(i>10): break\n",
    "    link = a.get('href')\n",
    "    if not re.search('ZIP', link): continue\n",
    "    full_link = 'https://2019.elections.openknowledge.be/live/' + link\n",
    "    \n",
    "    r = requests.get(full_link)\n",
    "    \n",
    "    filename = 'data_verkiezingsuitslagen/zipfiles/'+link\n",
    "    with open(filename, \"wb\") as handle:\n",
    "        for data in r.iter_content():\n",
    "            handle.write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip all ZIP files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir('data_verkiezingsuitslagen/zipfiles/'):\n",
    "    if not re.search('ZIP', file): continue\n",
    "    print('Unzizipping {}'.format(file))\n",
    "    zip_ref = zipfile.ZipFile('data_verkiezingsuitslagen/zipfiles/' + file, 'r')\n",
    "    zip_ref.extractall('data_verkiezingsuitslagen/xmls/')\n",
    "    zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand filenames\n",
    "\n",
    "- Enkel files van de Kamer: CK\n",
    "- Geen tussentijdse bestanden, dus geen _[0-9][0-9][0-9]_ in de filename, zie handleiding\n",
    "- Dit zijn allemaal bestanden van Kanton hoofdbureaus\n",
    "\n",
    "- Enkel NL bestanden, geen tweetalige bestanden. _NL.xml in de filename, en niet _NL_FR.xml of _FR_NL.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_files = []\n",
    "for file in os.listdir('data_verkiezingsuitslagen/xmls/'):\n",
    "    if not re.search('EML', file): continue\n",
    "    #if re.search('_NL_FR.EML', file) or re.search('_FR_NL.EML', file): continue\n",
    "    if not re.search('_CK', file): continue\n",
    "    if  re.search('_[0-9][0-9][0-9]_', file): continue\n",
    "    print(file)\n",
    "    interesting_files.append(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop over files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_kamer_file(filename):\n",
    "    soup = BeautifulSoup(open(filename), \"html.parser\")\n",
    "    contestname = soup.find('contestname').text\n",
    "    niscode = soup.find('contestidentifier').attrs['idnumber']\n",
    "    \n",
    "    candidates = []\n",
    "    partijen = []\n",
    "\n",
    "    for reportingunitvotes in soup.findAll('reportingunitvotes'):\n",
    "        partij = reportingunitvotes.reportingunitidentifier.text\n",
    "\n",
    "        for i, selection in enumerate(soup.findAll('selection')):\n",
    "            if selection.find('registeredname'): \n",
    "                #print(selection)\n",
    "                temp_dict = {'name':selection.registeredname.text, \n",
    "                                'validvotes':selection.validvotes.text, \n",
    "                            'niscode':niscode,\n",
    "                            'kanton':contestname}\n",
    "                for countmetric in selection.findAll('countmetric'):\n",
    "                    temp_dict[countmetric.attrs['type']] = countmetric.text\n",
    "                partijen.append(temp_dict)\n",
    "\n",
    "                continue\n",
    "            elif selection.find('candidate'):\n",
    "                candidates.append({'name': selection.candidate.knownas.text, \n",
    "                                  'votes': selection.validvotes.text, \n",
    "                                  'partij':partij, \n",
    "                                  'niscode': niscode, \n",
    "                                  'kanton': contestname})\n",
    "            #else:\n",
    "                #print(selection)\n",
    "\n",
    "    # Zitten blijkbaar dubbels in de partijen, elke record zit er 10 keer in?\n",
    "    partijen = pd.DataFrame(partijen).drop_duplicates().to_dict(orient='records')\n",
    "    candidates = pd.DataFrame(candidates).drop_duplicates().to_dict(orient='records')    \n",
    "                \n",
    "    return candidates, partijen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_total = []\n",
    "partijen_total = []\n",
    "for i, file in enumerate(interesting_files):\n",
    "    print(i)\n",
    "    candidates, partijen = parse_kamer_file('data_verkiezingsuitslagen/xmls/{}'.format(file))\n",
    "    candidates_total.extend(candidates)\n",
    "    partijen_total.extend(partijen)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to CSV and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_total = pd.DataFrame(candidates_total)\n",
    "candidates_total.to_csv('data_verkiezingsuitslagen/candidates_total.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partijen_total = pd.DataFrame(partijen_total)\n",
    "partijen_total.to_csv('data_verkiezingsuitslagen/partijen_total.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
